19-10-2025:
- What is the data model? How is the data organized?
- What are the features?
- Do we have to pick a subset of the features?
- Do we need to perform any filtering?
- How will the pipeline look like?
- What are we considering as a regression or an improvement?

26-10-2025:
- JVM and java bytecode? Tiered compilation?
- From my understanding of JVM and the whole process of Java compilation, what can we infer about the data we have?
- Based on what we learned and found above, we should find a subset of each default.csv that we are interested in. Which and how do we decide?
- Assume commits A and B, how can you define a regression that occurred due to commit B? How are you defining this "regression"?
- recap/elaborate on pipeline.

02-11-2025:
- Config? Parser? traverse and find the relevant datasets?
- Implement generic logger that will be used throughout the pipeline to log (info, warn, error)
- Set up the main dataset pipeline for filtering and merging the datasets
- Apply the "filter" on each found default.csv to detect steady state prior to merging them.
- Implement plotter and save pngs to directory.
