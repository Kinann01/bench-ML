### Cut off index cannot be in the end of the series

- detect_cutoff_index() now checks where the cutoff index is. If it is in the last 30% of the series then we fall back to picking something random between 10% and 50% percent of the series.

### Define a metrice to evaluate "spikeness" in the data

- We want to find a way to be able to say that a given data frame is too spikey / too noisy. We need to define a metric and a unit. This is implemneted in DataSetUtil.

### Version

- In pipeline.py, prior to merging, I added a new feature to each dataframe called version, this is necessary to distinguish the datasets (i.e. time and repo).


### DataSetUtil

- note that the term dataset now refers to the full dataset X i.e. after we have merged datasets X_1 to X_n where i in {1, ... , N} corresponds to the commit.

- Implemented /src/util.py which contains a DataSetUtil class. The main goal of this class is to provide access to metadata and relevant metrics of a given dataset. It will be the class responsible for exposing information like the relevant config, the versions associated, the spikeness/noise metrics and other things which might be necessary for the analyzer. 

- So, given a dataset, based on the information obtained from the utils, we will be able to perform one of the following actions

  1) Analyze using ML techcniques
  2) No analysis needed but report to the user
  3) No analysis needed or drop. Might be related to incomplete data or data that has not yielded anything useful
  
- Contains the metric for calculating the spikeness of a given Path (dataset). See:
    * get_spikeness(self, path: Path) -> float: 
    * calculate_spikeness(self, path: Path) -> float: 
    
- The spikeness is calcualted based on the coefficiant of variation with thresholds hardcoded based on expert judgement. We already have series that we can describe as very spiky, not spiky and medium spiky

- Also exposes a function called needs_analysis() - this is needed by the caller to know if we need the analysis to be performed or not but needs reporting. For example: a case where dataset under commit X is very noisy and spiky while is stable under commit Y. This will be hard to classify as a regression or improvement but something has obviously changed and hence is worth reporting.

```bash
Calculated spike level for /Users/kinanal-falakh/Desktop/bench-ML/measurement/29/98/66/8669829: 0.007935689449819424
Calculated spike level for /Users/kinanal-falakh/Desktop/bench-ML/measurement/88/97/66/8669788: 0.006323829397797817
Calculated spike level for /Users/kinanal-falakh/Desktop/bench-ML/measurement/48/18/74/8741848: 0.005736732576808114
Calculated spike level for /Users/kinanal-falakh/Desktop/bench-ML/measurement/88/00/67/8670088: 0.021634174169771918
Calculated spike level for /Users/kinanal-falakh/Desktop/bench-ML/measurement/13/19/74/8741913: 0.020972594102690444
Calculated spike level for /Users/kinanal-falakh/Desktop/bench-ML/measurement/92/32/77/8773292: 0.06411735336684928
Calculated spike level for /Users/kinanal-falakh/Desktop/bench-ML/measurement/08/32/77/8773208: 0.06294280029874906
Calculated spike level for /Users/kinanal-falakh/Desktop/bench-ML/measurement/24/04/68/8680424: 0.06705200179976255
Calculated spike level for /Users/kinanal-falakh/Desktop/bench-ML/measurement/09/87/76/8768709: 0.007661582589056689
Calculated spike level for /Users/kinanal-falakh/Desktop/bench-ML/measurement/30/02/67/8670230: 0.010714105504737951
Calculated spike level for /Users/kinanal-falakh/Desktop/bench-ML/measurement/41/00/67/8670041: 0.013790262284626213
Calculated spike level for /Users/kinanal-falakh/Desktop/bench-ML/measurement/25/19/74/8741925: 0.010948628553525998
Calculated spike level for /Users/kinanal-falakh/Desktop/bench-ML/measurement/21/28/74/8742821: 0.00675643480183224
Calculated spike level for /Users/kinanal-falakh/Desktop/bench-ML/measurement/96/10/67/8671096: 0.006871398274056746
```

- based on the above values of already seen plots. The thresholds were chosen
-
